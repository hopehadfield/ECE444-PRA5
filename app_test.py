import pytest
import requests
import time
import csv

from .application import app

@pytest.fixture
def client():
    app.config["TESTING"] = True

    with app.app_context():
        yield app.test_client()  # tests run here

def test_inputs(client):
    input_data = [{"text": "This is fake news."},
                  {"text": "This is real news."},
                  {"text": "More fake news."},
                  {"text": "More real news."}]
    for input in input_data:
        response = client.post('/predict', json=input)
        if input["text"].lower().find("fake") >= 0:
            assert response.text == 'FAKE'
        else:
            assert response.text == 'REAL'

def test_performance():
    input_data = [
        {"text": "This is fake news."},
        {"text": "This is real news."},
        {"text": "More fake news."},
        {"text": "More real news."}
    ]
    
    results = []
    
    for i, input_item in enumerate(input_data):
        case_results = []
        for _ in range(100):  # 100 API calls per test case
            start_time = time.time()
            # response = request.post(f"{'Ece444-pra5-app-env-final-redo.eba-yhhrtmxf.us-east-2.elasticbeanstalk.com'}/predict", json=input_item)
            response = requests.post(f"Ece444-pra5-app-env-final-redo.eba-yhhrtmxf.us-east-2.elasticbeanstalk.com/predict", json=input_item)
            end_time = time.time()
            latency = end_time - start_time
            case_results.append({
                'case': i,
                'input': input_item['text'],
                'latency': latency,
                'timestamp': time.time(),
                'prediction': response.text
            })
        results.extend(case_results)
    
    # Save results to CSV
    with open('latency_results.csv', 'w', newline='') as csvfile:
        fieldnames = ['case', 'input', 'latency', 'timestamp', 'prediction']
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writeheader()
        for row in results:
            writer.writerow(row)

    # Assertions to ensure the test passes
    assert len(results) == 400, "Expected 400 total results (100 per test case)"

    # test_performance() generated by Cursor using first test case and prompt to create a csv file with 100 API calls and edited by me.